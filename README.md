
## **EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS**

### **AIM:**

To test and compare how different pattern models respond to various prompts — naïve (broad or unstructured) versus basic (clear, detailed, and structured) — across multiple scenarios and analyze the quality, accuracy, and depth of the generated responses.

---

### **AI TOOLS REQUIRED:**

* ChatGPT (GPT-5 model or equivalent generative AI tool)

---

### **EXPLANATION:**

#### **1. Define the Two Prompt Types:**

* **Naïve Prompt:**
  A short, broad, or unstructured instruction with minimal detail or context.
  Example: *“Write a story.”*

* **Basic Prompt:**
  A clear, detailed, and structured instruction that specifies context, tone, or constraints.
  Example: *“Write a short story about a young astronaut who discovers a new planet filled with mathematical patterns. Keep it engaging for high school students.”*

---

### **2. Test Scenarios**

We have selected **four test scenarios** for comparison:

1. **Creative Story Generation**
2. **Factual Question Answering**
3. **Summarization**
4. **Advice/Recommendation**

For each, both a naïve and a basic prompt were tested in ChatGPT.

---

### **3. Experimental Observations**

| **Scenario**                 | **Naïve Prompt**            | **Basic Prompt**                                                                              | **Naïve Output Summary**                          | **Basic Output Summary**                                         | **Quality**       | **Accuracy** | **Depth** |
| ---------------------------- | --------------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------- | ---------------------------------------------------------------- | ----------------- | ------------ | --------- |
| **1. Creative Story**        | “Write a story.”            | “Write a 150-word story about a robot who learns human emotions while exploring Mars.”        | Simple, generic story without focus or structure. | Well-developed plot, emotion, and setting; concise and creative. | Basic prompt high | Moderate     | Strong    |
| **2. Factual Question**      | “What is AI?”               | “Explain Artificial Intelligence, its types, and one real-world application in simple terms.” | Short definition only.                            | Detailed, clear explanation with examples.                       | Basic prompt high | High         | High      |
| **3. Summarization**         | “Summarize photosynthesis.” | “Summarize the process of photosynthesis in 4–5 lines suitable for a 6th-grade student.”      | Technical explanation; not concise.               | Simplified, accurate summary; suitable for age group.            | High              | High         | High      |
| **4. Advice/Recommendation** | “Give me study tips.”       | “Give 5 practical study tips for engineering students to improve focus and exam performance.” | Generic suggestions.                              | Tailored, specific, and actionable tips.                         | High              | High         | High      |

---

### **4. Analysis**

* **Prompt Clarity Impact:**
  The results show that **structured prompts** (basic prompts) consistently produce more relevant, accurate, and context-aware responses.
* **Naïve Prompts:**
  Often produce vague, generic, or short outputs lacking depth or precision.
* **Basic Prompts:**
  Guide the model effectively by providing context, leading to richer, targeted, and better-organized responses.

**Observation:**
While naïve prompts sometimes generate creative outputs (especially in storytelling), overall quality and factual accuracy improve significantly with basic prompts.

---

### **5. Summary of Findings**

| **Parameter**   | **Naïve Prompt** | **Basic Prompt** |
| --------------- | ---------------- | ---------------- |
| **Clarity**     | Low              | High             |
| **Relevance**   | Medium           | High             |
| **Accuracy**    | Medium           | High             |
| **Depth**       | Limited          | Detailed         |
| **Consistency** | Variable         | Consistent       |

---

<img width="1024" height="1536" alt="image" src="https://github.com/user-attachments/assets/b297a7bf-926a-430f-b0c4-c5536d724c3a" />


### **6. Conclusion**

Prompt design directly affects the **quality, accuracy, and depth** of AI-generated outputs.
Structured and context-rich prompts (basic prompts) consistently yield **more meaningful and reliable** responses.
Therefore, **prompt engineering** is essential for optimizing performance when interacting with AI systems like ChatGPT.

---

### **RESULT:**

The experiment on “Comparative Analysis of Different Types of Prompting Patterns” was executed successfully. The results confirm that **well-structured (basic) prompts produce superior output** compared to naïve prompts across various scenarios.

---

Would you like me to format this as a **Word (DOCX)** or **PDF report** for submission? I can generate it for you.
